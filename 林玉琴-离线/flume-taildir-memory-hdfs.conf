a1.sources = r1 r2 r3 r4 r5 r6 r7
a1.sinks = k1 k2 k3 k4 k5 k6 k7
a1.channels = c1 c2 c3 c4 c5 c6 c7

#atm-entry
a1.sources.r1.type = taildir
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /opt/data/data/log/atm-entry.*\.log
a1.sources.r1.headers.f1.headerKey1 = atm-entry
a1.sources.r1.positionFile = /opt/data/logs/flume_postion1.json

a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = hdfs://hadoop01:9000/flume/%Y-%m-%d/ATM
a1.sinks.k1.hdfs.rollInterval = 30 
a1.sinks.k1.hdfs.rollSize = 5242880
a1.sinks.k1.hdfs.rollCount = 0
a1.sinks.k1.hdfs.filePrefix = log_atm_entry_%H
a1.sinks.k1.hdfs.fileSuffix = .log
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.useLocalTimeStamp = true

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1





#atm-server
a1.sources.r2.type = taildir
a1.sources.r2.filegroups = f2
a1.sources.r2.filegroups.f2 = /opt/data/data/log/atm-server.*\.log
a1.sources.r2.headers.f2.headerKey1 = atm-server
a1.sources.r2.positionFile = /opt/data/logs/flume_postion2.json

a1.sinks.k2.type = hdfs
a1.sinks.k2.hdfs.path = hdfs://hadoop01:9000/flume/%Y-%m-%d/ATM
a1.sinks.k2.hdfs.rollInterval = 30 
a1.sinks.k2.hdfs.rollSize = 5242880
a1.sinks.k2.hdfs.rollCount = 0
a1.sinks.k2.hdfs.filePrefix = log_atm_server_%H
a1.sinks.k2.hdfs.fileSuffix = .log
a1.sinks.k2.hdfs.fileType=DataStream
a1.sinks.k2.hdfs.useLocalTimeStamp = true

a1.channels.c2.type = memory
a1.channels.c2.capacity = 1000
a1.channels.c2.transactionCapacity = 100

a1.sources.r2.channels = c2
a1.sinks.k2.channel = c2





#core-service 
a1.sources.r3.type = taildir
a1.sources.r3.filegroups = f3
a1.sources.r3.filegroups.f3=/opt/data/data/log/core-service.*\.log
a1.sources.r3.headers.f3.headerKey1 = core-service
a1.sources.r3.positionFile = /opt/data/logs/flume_postion3.json

a1.sinks.k3.type = hdfs
a1.sinks.k3.hdfs.path = hdfs://hadoop01:9000/flume/%Y-%m-%d/ATM
a1.sinks.k3.hdfs.rollInterval = 30
a1.sinks.k3.hdfs.rollSize = 5242880
a1.sinks.k3.hdfs.rollCount = 0
a1.sinks.k3.hdfs.filePrefix = log_core_service_%H
a1.sinks.k3.hdfs.fileSuffix = .log
a1.sinks.k3.hdfs.fileType = DataStream
a1.sinks.k3.hdfs.useLocalTimeStamp = true

a1.channels.c3.type = memory
a1.channels.c3.capacity = 1000
a1.channels.c3.transactionCapacity =100

a1.sources.r3.channels = c3
a1.sinks.k3.channel = c3





#core-service 
a1.sources.r4.type = taildir
a1.sources.r4.filegroups = f4
a1.sources.r4.filegroups.f4=/opt/data/data/log/core-service.*\.log
a1.sources.r4.headers.f4.headerKey1 = core-service
a1.sources.r4.positionFile = /opt/data/logs/flume_postion4.json

a1.sinks.k4.type = hdfs
a1.sinks.k4.hdfs.path = hdfs://hadoop01:9000/flume/%Y-%m-%d/FX
a1.sinks.k4.hdfs.rollInterval = 30
a1.sinks.k4.hdfs.rollSize = 5242880
a1.sinks.k4.hdfs.rollCount = 0
a1.sinks.k4.hdfs.filePrefix = log_core_service_%H
a1.sinks.k4.hdfs.fileSuffix = .log
a1.sinks.k4.hdfs.fileType = DataStream
a1.sinks.k4.hdfs.useLocalTimeStamp = true

a1.channels.c4.type = memory
a1.channels.c4.capacity = 1000
a1.channels.c4.transactionCapacity =100

a1.sources.r4.channels = c4
a1.sinks.k4.channel = c4





# fx-entry 
a1.sources.r5.type = taildir
a1.sources.r5.filegroups = f5
a1.sources.r5.filegroups.f5=/opt/data/data/log/fx-entry.*\.log
a1.sources.r5.headers.f5.headerKey1 = fx-entry
a1.sources.r5.positionFile = /opt/data/logs/flume_postion5.json

a1.sinks.k5.type = hdfs
a1.sinks.k5.hdfs.path=hdfs://hadoop01:9000/flume/%Y-%m-%d/FX
a1.sinks.k5.hdfs.rollInterval = 30 
a1.sinks.k5.hdfs.rollSize=5242880
a1.sinks.k5.hdfs.rollCount=0
a1.sinks.k5.hdfs.filePrefix=log_fx_entry_%H
a1.sinks.k5.hdfs.fileSuffix=.log
a1.sinks.k5.hdfs.fileType=DataStream
a1.sinks.k5.hdfs.useLocalTimeStamp = true

a1.channels.c5.type = memory
a1.channels.c5.capacity = 1000
a1.channels.c5.transactionCapacity = 100

a1.sources.r5.channels = c5
a1.sinks.k5.channel = c5





# fx-server 
a1.sources.r6.type = taildir
a1.sources.r6.filegroups = f6
a1.sources.r6.filegroups.f6 = /opt/data/data/log/fx-server.*\.log
a1.sources.r6.headers.f6.headerKey1 = fx-server
a1.sources.r6.positionFile = /opt/data/logs/flume_postion6.json

a1.sinks.k6.type = hdfs
a1.sinks.k6.hdfs.path = hdfs://hadoop01:9000/flume/%Y-%m-%d/FX
a1.sinks.k6.hdfs.rollInterval = 30 
a1.sinks.k6.hdfs.rollSize = 5242880
a1.sinks.k6.hdfs.rollCount = 0
a1.sinks.k6.hdfs.filePrefix = log_fx_server_%H
a1.sinks.k6.hdfs.fileSuffix = .log
a1.sinks.k6.hdfs.fileType = DataStream
a1.sinks.k6.hdfs.useLocalTimeStamp = true

a1.channels.c6.type = memory
a1.channels.c6.capacity = 1000
a1.channels.c6.transactionCapacity = 100

a1.sources.r6.channels = c6
a1.sinks.k6.channel = c6





# fx-core-entry 
a1.sources.r7.type = taildir
a1.sources.r7.filegroups = f7
a1.sources.r7.filegroups.f7 = /opt/data/data/log/fx-core-entry.*\.log
a1.sources.r7.headers.f7.headerKey1 = fx-core-entry
a1.sources.r7.positionFile = /opt/data/logs/flume_postion6.json

a1.sinks.k7.type = hdfs
a1.sinks.k7.hdfs.path = hdfs://hadoop01:9000/flume/%Y-%m-%d/FX
a1.sinks.k7.hdfs.rollInterval = 30 
a1.sinks.k7.hdfs.rollSize = 5242880
a1.sinks.k7.hdfs.rollCount = 0
a1.sinks.k7.hdfs.filePrefix = log_fx_core_entry_%H
a1.sinks.k7.hdfs.fileSuffix = .log
a1.sinks.k7.hdfs.fileType = DataStream
a1.sinks.k7.hdfs.useLocalTimeStamp = true

a1.channels.c7.type = memory
a1.channels.c7.capacity = 1000
a1.channels.c7.transactionCapacity = 100

a1.sources.r7.channels = c7
a1.sinks.k7.channel = c7
